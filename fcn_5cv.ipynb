{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "7922e149-72fa-48cd-a545-b70bddb40d28",
    "_uuid": "9341f2516086ca38bca96e06a9dbfc39f813a95a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import utils \n",
    "from utils import *\n",
    "from keras.callbacks import ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams['figure.figsize'] = 10, 10\n",
    "# %matplotlib inline\n",
    "exp_name = \"_5fold_fcn\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "9d5839b6-f7fb-426d-b05f-cf2dba9313a8",
    "_uuid": "d375d4f754ad7fb77db2142c7c075b4ad4168390"
   },
   "outputs": [],
   "source": [
    "train = pd.read_json(\"data/input/train.json\")\n",
    "target_train=train['is_iceberg']\n",
    "test = pd.read_json(\"data/input/test.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['inc_angle']=pd.to_numeric(test['inc_angle'], errors='coerce')\n",
    "train['inc_angle']=pd.to_numeric(train['inc_angle'], errors='coerce')#We have only 133 NAs.\n",
    "train['inc_angle']=train['inc_angle'].fillna(method='pad')\n",
    "X_angle=train['inc_angle']\n",
    "X_test_angle=test['inc_angle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_weights = {0:}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Generate the training data\n",
    "X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\n",
    "X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\n",
    "X_band_3=(X_band_1+X_band_2)/2\n",
    "#X_band_3=np.array([np.full((75, 75), angel).astype(np.float32) for angel in train[\"inc_angle\"]])\n",
    "X_train = np.concatenate([X_band_1[:, :, :, np.newaxis]\n",
    "                          , X_band_2[:, :, :, np.newaxis]\n",
    "                         , X_band_3[:, :, :, np.newaxis]], axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "X_band_test_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_1\"]])\n",
    "X_band_test_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_2\"]])\n",
    "X_band_test_3=(X_band_test_1+X_band_test_2)/2\n",
    "#X_band_test_3=np.array([np.full((75, 75), angel).astype(np.float32) for angel in test[\"inc_angle\"]])\n",
    "X_test = np.concatenate([X_band_test_1[:, :, :, np.newaxis]\n",
    "                          , X_band_test_2[:, :, :, np.newaxis]\n",
    "                         , X_band_test_3[:, :, :, np.newaxis]], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the image transformations here\n",
    "gen = ImageDataGenerator(horizontal_flip = True,\n",
    "                         vertical_flip = True,\n",
    "                         width_shift_range = 0.,\n",
    "                         height_shift_range = 0.,\n",
    "                         channel_shift_range=0,\n",
    "                         zoom_range = 0.2,\n",
    "                         rotation_range = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Here is the function that merges our two generators\n",
    "# We use the exact same generator with the same random seed for both the y and angle arrays\n",
    "def gen_flow_for_two_inputs(X1, X2, y):\n",
    "    genX1 = gen.flow(X1,y,  batch_size=batch_size,seed=55)\n",
    "    genX2 = gen.flow(X1,X2, batch_size=batch_size,seed=55)\n",
    "    while True:\n",
    "            X1i = genX1.next()\n",
    "            X2i = genX2.next()\n",
    "            #Assert arrays are equal - this was for peace of mind, but slows down training\n",
    "            #np.testing.assert_array_equal(X1i[0],X2i[0])\n",
    "            yield [X1i[0], X2i[1]], X1i[1]\n",
    "\n",
    "# Finally create generator\n",
    "def get_callbacks(filepath, patience=6, min_lr=1e-6):\n",
    "    es = EarlyStopping('val_loss', patience=patience)\n",
    "    msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "    lrplateu = ReduceLROnPlateau(monitor='val_loss',  patience=3, verbose=1, factor=0.5, min_lr=min_lr)\n",
    "\n",
    "    return [es, msave,lrplateu]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_7 (InputLayer)             (None, 75, 75, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)            (None, 75, 75, 64)    1792        input_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)            (None, 75, 75, 64)    36928       block1_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)       (None, 37, 37, 64)    0           block1_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)            (None, 37, 37, 128)   73856       block1_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)            (None, 37, 37, 128)   147584      block2_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)       (None, 18, 18, 128)   0           block2_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)            (None, 18, 18, 256)   295168      block2_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)            (None, 18, 18, 256)   590080      block3_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)            (None, 18, 18, 256)   590080      block3_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)       (None, 9, 9, 256)     0           block3_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)            (None, 9, 9, 512)     1180160     block3_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)            (None, 9, 9, 512)     2359808     block4_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)            (None, 9, 9, 512)     2359808     block4_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)       (None, 4, 4, 512)     0           block4_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "fcn_top (Conv2D)                 (None, 4, 4, 512)     2359808     block4_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNor (None, 4, 4, 512)     16          fcn_top[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)               (None, 4, 4, 512)     2359808     batch_normalization_19[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNor (None, 4, 4, 512)     16          conv2d_19[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)               (None, 4, 4, 512)     2359808     batch_normalization_20[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNor (None, 4, 4, 512)     16          conv2d_20[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "angle (InputLayer)               (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "global_max_pooling2d_7 (GlobalMa (None, 512)           0           batch_normalization_21[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dense_13 (Dense)                 (None, 1)             2           angle[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)      (None, 513)           0           global_max_pooling2d_7[0][0]     \n",
      "                                                                   dense_13[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "fc2 (Dense)                      (None, 512)           263168      concatenate_7[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)             (None, 512)           0           fc2[0][0]                        \n",
      "____________________________________________________________________________________________________\n",
      "fc3 (Dense)                      (None, 512)           262656      dropout_13[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)             (None, 512)           0           fc3[0][0]                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_14 (Dense)                 (None, 1)             513         dropout_14[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 15,241,075\n",
      "Trainable params: 7,605,787\n",
      "Non-trainable params: 7,635,288\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "getModel().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 75, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_cell_guid": "067f3dd7-3dcf-4b71-857d-e00b4afbd06e",
    "_uuid": "af8be6ce23dba815bbde23fd7e196eb54ae7c4e1"
   },
   "outputs": [],
   "source": [
    "dropout = 0.3\n",
    "nf = 512\n",
    "batch_size=128\n",
    "\n",
    "def getModel():\n",
    "    input_2 = Input(shape=[1], name=\"angle\")\n",
    "    angle_layer = Dense(1, )(input_2)\n",
    "    \n",
    "    \n",
    "    base_model = VGG16(weights='imagenet', include_top=False, \n",
    "                 input_shape=X_train.shape[1:], classes=1)\n",
    "    for l in base_model.layers:\n",
    "        l.trainable = False\n",
    "        \n",
    "    x = base_model.get_layer('block4_pool').output\n",
    "    \n",
    "    \n",
    "    x = Convolution2D(nf,(3,3), activation='relu', padding='same', name=\"fcn_top\")(x)\n",
    "    x = BatchNormalization(axis=1)(x)    \n",
    "    \n",
    "    x = Convolution2D(nf,(3,3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization(axis=1)(x)    \n",
    "    \n",
    "    x = Convolution2D(nf,(3,3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization(axis=1)(x)    \n",
    "#     x = MaxPooling2D()(x)    \n",
    "    \n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    \n",
    "    \n",
    "    merge_one = concatenate([x, angle_layer])\n",
    "    merge_one = Dense(512, activation='relu', name='fc2')(merge_one)\n",
    "    merge_one = Dropout(0.3)(merge_one)\n",
    "    merge_one = Dense(512, activation='relu', name='fc3')(merge_one)\n",
    "    merge_one = Dropout(0.3)(merge_one)\n",
    "    \n",
    "    predictions = Dense(1, activation='sigmoid')(merge_one)\n",
    "    \n",
    "    model = Model(inputs=[base_model.input, input_2], outputs=predictions)\n",
    "    \n",
    "#     sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=Adam(lr=1e-3),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "#Using K-fold Cross Validation with Data Augmentation.\n",
    "def trainKfold(X_train, X_angle, X_test):\n",
    "    K=5\n",
    "    folds = list(StratifiedKFold(n_splits=K, shuffle=True, random_state=17).split(X_train, target_train))\n",
    "    y_test_pred_log = 0\n",
    "    y_train_pred_log=0\n",
    "    y_valid_pred_log = 0.0*target_train\n",
    "    \n",
    "    \n",
    "    for j, (train_idx, test_idx) in enumerate(folds):\n",
    "        print('\\n===================FOLD=',j+1)\n",
    "        X_train_cv = X_train[train_idx]\n",
    "        y_train_cv = target_train[train_idx]\n",
    "        X_holdout = X_train[test_idx]\n",
    "        Y_holdout= target_train[test_idx]\n",
    "        \n",
    "        #Angle\n",
    "        X_angle_cv=X_angle[train_idx]\n",
    "        X_angle_hold=X_angle[test_idx]\n",
    "\n",
    "        #define file path and get callbacks\n",
    "        file_path = \"weights/{}_{}.hdf5\".format(exp_name,j+1)\n",
    "        callbacks = get_callbacks(filepath=file_path, patience=10,min_lr=1e-6)\n",
    "        gen_flow = gen_flow_for_two_inputs(X_train_cv, X_angle_cv, y_train_cv)\n",
    "        \n",
    "        model= getModel()\n",
    "        model.fit_generator(\n",
    "                gen_flow,\n",
    "                steps_per_epoch=train.shape[0]/batch_size,\n",
    "                epochs=100,\n",
    "                shuffle=True,\n",
    "                verbose=1,\n",
    "                validation_data=([X_holdout,X_angle_hold], Y_holdout),\n",
    "                callbacks=callbacks)\n",
    "        \n",
    "        \n",
    "#         for l in model.layers:\n",
    "#             l.trainable = True        \n",
    "#         model.lr.set_value(1e-5)\n",
    "#         callbacks = get_callbacks(filepath=file_path, patience=10,min_lr=1e-6)\n",
    "\n",
    "#         model.fit_generator(\n",
    "#                 gen_flow,\n",
    "#                 steps_per_epoch=train.shape[0]/batch_size,\n",
    "#                 epochs=100,\n",
    "#                 shuffle=True,\n",
    "#                 verbose=1,\n",
    "#                 validation_data=([X_holdout,X_angle_hold], Y_holdout),\n",
    "#                 callbacks=callbacks)        \n",
    "        \n",
    "        \n",
    "        #Getting the Best Model\n",
    "        model.load_weights(filepath=file_path)\n",
    "        #Getting Training Score\n",
    "        score = model.evaluate([X_train_cv,X_angle_cv], y_train_cv, verbose=0)\n",
    "        print('Train loss:', score[0])\n",
    "        print('Train accuracy:', score[1])\n",
    "        \n",
    "        #Getting Test Score\n",
    "        score = model.evaluate([X_holdout,X_angle_hold], Y_holdout, verbose=0)\n",
    "        print('Test loss:', score[0])\n",
    "        print('Test accuracy:', score[1])\n",
    "\n",
    "        #Getting validation Score.\n",
    "        pred_valid=model.predict([X_holdout,X_angle_hold])\n",
    "        y_valid_pred_log[test_idx] = pred_valid.reshape(pred_valid.shape[0])\n",
    "\n",
    "        #Getting Test Scores\n",
    "        temp_test=model.predict([X_test, X_test_angle])\n",
    "        y_test_pred_log+=temp_test.reshape(temp_test.shape[0])\n",
    "\n",
    "        #Getting Train Scores\n",
    "        temp_train=model.predict([X_train, X_angle])\n",
    "        y_train_pred_log+=temp_train.reshape(temp_train.shape[0])\n",
    "\n",
    "    y_test_pred_log=y_test_pred_log/K\n",
    "    y_train_pred_log=y_train_pred_log/K\n",
    "\n",
    "    \n",
    "    train_log_loss = log_loss(target_train, y_train_pred_log) \n",
    "    valid_log_loss = log_loss(target_train, y_valid_pred_log)\n",
    "    \n",
    "    print('\\n Train Log Loss Validation= ',train_log_loss)\n",
    "    print(' Valid Log Loss Validation= ',valid_log_loss)\n",
    "    \n",
    "    \n",
    "    return y_train_pred_log, y_valid_pred_log, y_test_pred_log, train_log_loss, valid_log_loss\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_cell_guid": "ea82458f-f41c-4abb-87aa-0dfc7a447969",
    "_uuid": "d462c689ee61d4c1cdcee42c7ded6c7c31c9cddc",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\n===================FOLD=', 1)\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 19s - loss: 1.7936 - acc: 0.5098 - val_loss: 7.5585 - val_acc: 0.5311\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 14s - loss: 0.8331 - acc: 0.4884 - val_loss: 7.5585 - val_acc: 0.5311\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 14s - loss: 0.7774 - acc: 0.4838 - val_loss: 7.5585 - val_acc: 0.5311\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 14s - loss: 0.7070 - acc: 0.5624 - val_loss: 6.7996 - val_acc: 0.5311\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 14s - loss: 0.6173 - acc: 0.6685 - val_loss: 1.0683 - val_acc: 0.7143\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 14s - loss: 0.4697 - acc: 0.7837 - val_loss: 1.2550 - val_acc: 0.6677\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 14s - loss: 0.4109 - acc: 0.7974 - val_loss: 0.5305 - val_acc: 0.8043\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 14s - loss: 0.3985 - acc: 0.8119 - val_loss: 0.6812 - val_acc: 0.7360\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 14s - loss: 0.6670 - acc: 0.6483 - val_loss: 2.1514 - val_acc: 0.5559\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 14s - loss: 0.5363 - acc: 0.7353 - val_loss: 1.3057 - val_acc: 0.6335\n",
      "Epoch 11/100\n",
      "11/12 [==========================>...] - ETA: 1s - loss: 0.4354 - acc: 0.7699\n",
      "Epoch 00010: reducing learning rate to 0.000500000023749.\n",
      "12/12 [==============================] - 14s - loss: 0.4482 - acc: 0.7511 - val_loss: 0.6566 - val_acc: 0.7112\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 14s - loss: 0.4617 - acc: 0.8009 - val_loss: 0.3228 - val_acc: 0.8571\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 13s - loss: 0.4178 - acc: 0.8092 - val_loss: 0.8027 - val_acc: 0.7174\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 14s - loss: 0.4604 - acc: 0.7819 - val_loss: 0.8717 - val_acc: 0.6553\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 14s - loss: 0.5239 - acc: 0.7124 - val_loss: 0.8767 - val_acc: 0.5652\n",
      "Epoch 16/100\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.4384 - acc: 0.7827\n",
      "Epoch 00015: reducing learning rate to 0.000250000011874.\n",
      "12/12 [==============================] - 14s - loss: 0.4331 - acc: 0.7856 - val_loss: 0.5136 - val_acc: 0.7360\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 14s - loss: 0.3232 - acc: 0.8473 - val_loss: 0.5311 - val_acc: 0.7671\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 14s - loss: 0.3262 - acc: 0.8499 - val_loss: 0.3629 - val_acc: 0.8354\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 14s - loss: 0.3213 - acc: 0.8545 - val_loss: 0.2785 - val_acc: 0.8851\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 14s - loss: 0.3258 - acc: 0.8597 - val_loss: 0.3130 - val_acc: 0.8665\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 14s - loss: 0.4599 - acc: 0.7951 - val_loss: 0.2848 - val_acc: 0.8820\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 14s - loss: 0.3309 - acc: 0.8339 - val_loss: 0.2789 - val_acc: 0.8820\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 14s - loss: 0.3242 - acc: 0.8669 - val_loss: 0.2678 - val_acc: 0.8913\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 14s - loss: 0.3467 - acc: 0.8219 - val_loss: 0.2672 - val_acc: 0.8944\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 14s - loss: 0.3136 - acc: 0.8630 - val_loss: 0.2751 - val_acc: 0.9006\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 14s - loss: 0.3181 - acc: 0.8291 - val_loss: 0.2618 - val_acc: 0.8975\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 14s - loss: 0.3889 - acc: 0.8153 - val_loss: 0.3006 - val_acc: 0.8665\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 14s - loss: 0.3840 - acc: 0.7956 - val_loss: 0.2787 - val_acc: 0.8820\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 14s - loss: 0.3462 - acc: 0.8381 - val_loss: 0.3138 - val_acc: 0.8478\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 14s - loss: 0.2992 - acc: 0.8735 - val_loss: 0.2532 - val_acc: 0.9068\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 14s - loss: 0.2932 - acc: 0.8748 - val_loss: 0.2481 - val_acc: 0.9006\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 14s - loss: 0.3517 - acc: 0.8101 - val_loss: 0.2965 - val_acc: 0.8634\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 14s - loss: 0.4860 - acc: 0.7589 - val_loss: 0.5428 - val_acc: 0.7050\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 14s - loss: 0.3887 - acc: 0.8042 - val_loss: 0.3162 - val_acc: 0.8975\n",
      "Epoch 35/100\n",
      "11/12 [==========================>...] - ETA: 1s - loss: 0.5313 - acc: 0.7628\n",
      "Epoch 00034: reducing learning rate to 0.000125000005937.\n",
      "12/12 [==============================] - 14s - loss: 0.5088 - acc: 0.7668 - val_loss: 0.5028 - val_acc: 0.7205\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 14s - loss: 0.3512 - acc: 0.8460 - val_loss: 0.4576 - val_acc: 0.7547\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 14s - loss: 0.3487 - acc: 0.8755 - val_loss: 0.2742 - val_acc: 0.8944\n",
      "Epoch 38/100\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.3047 - acc: 0.8693\n",
      "Epoch 00037: reducing learning rate to 6.25000029686e-05.\n",
      "12/12 [==============================] - 14s - loss: 0.3051 - acc: 0.8682 - val_loss: 0.2864 - val_acc: 0.8727\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 14s - loss: 0.3617 - acc: 0.8317 - val_loss: 0.2416 - val_acc: 0.8944\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 14s - loss: 0.2946 - acc: 0.8689 - val_loss: 0.2336 - val_acc: 0.9130\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 14s - loss: 0.3195 - acc: 0.8297 - val_loss: 0.2642 - val_acc: 0.8975\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 14s - loss: 0.2841 - acc: 0.8774 - val_loss: 0.2534 - val_acc: 0.9037\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 14s - loss: 0.2898 - acc: 0.8702 - val_loss: 0.2411 - val_acc: 0.8975\n",
      "Epoch 44/100\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.2729 - acc: 0.8849\n",
      "Epoch 00043: reducing learning rate to 3.12500014843e-05.\n",
      "12/12 [==============================] - 14s - loss: 0.3312 - acc: 0.8544 - val_loss: 0.2343 - val_acc: 0.9006\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 14s - loss: 0.3014 - acc: 0.8748 - val_loss: 0.2409 - val_acc: 0.9006\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 14s - loss: 0.2933 - acc: 0.8833 - val_loss: 0.2349 - val_acc: 0.9006\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 14s - loss: 0.2669 - acc: 0.8840 - val_loss: 0.2307 - val_acc: 0.9099\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 14s - loss: 0.2893 - acc: 0.8761 - val_loss: 0.2285 - val_acc: 0.9130\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 14s - loss: 0.2809 - acc: 0.8722 - val_loss: 0.2273 - val_acc: 0.9068\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 14s - loss: 0.4349 - acc: 0.8330 - val_loss: 0.2276 - val_acc: 0.9037\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 14s - loss: 0.2908 - acc: 0.8741 - val_loss: 0.2280 - val_acc: 0.9068\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 14s - loss: 0.3174 - acc: 0.8755 - val_loss: 0.2286 - val_acc: 0.9099\n",
      "Epoch 53/100\n",
      "11/12 [==========================>...] - ETA: 1s - loss: 0.3708 - acc: 0.8253\n",
      "Epoch 00052: reducing learning rate to 1.56250007421e-05.\n",
      "12/12 [==============================] - 14s - loss: 0.3575 - acc: 0.8330 - val_loss: 0.2292 - val_acc: 0.9130\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 14s - loss: 0.2692 - acc: 0.8833 - val_loss: 0.2294 - val_acc: 0.9130\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 14s - loss: 0.2825 - acc: 0.8557 - val_loss: 0.2297 - val_acc: 0.9130\n",
      "Epoch 56/100\n",
      "10/12 [========================>.....] - ETA: 2s - loss: 0.2999 - acc: 0.8695\n",
      "Epoch 00055: reducing learning rate to 7.81250037107e-06.\n",
      "12/12 [==============================] - 14s - loss: 0.3292 - acc: 0.8343 - val_loss: 0.2292 - val_acc: 0.9130\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 14s - loss: 0.2915 - acc: 0.8774 - val_loss: 0.2289 - val_acc: 0.9130\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 14s - loss: 0.3395 - acc: 0.8350 - val_loss: 0.2287 - val_acc: 0.9130\n",
      "Epoch 59/100\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.2821 - acc: 0.8885\n",
      "Epoch 00058: reducing learning rate to 3.90625018554e-06.\n",
      "12/12 [==============================] - 14s - loss: 0.2847 - acc: 0.8853 - val_loss: 0.2282 - val_acc: 0.9161\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 14s - loss: 0.3323 - acc: 0.8382 - val_loss: 0.2281 - val_acc: 0.9161\n",
      "('Train loss:', 0.26802218174227688)\n",
      "('Train accuracy:', 0.88533541341653665)\n",
      "('Test loss:', 0.2272916375109868)\n",
      "('Test accuracy:', 0.90683229813664601)\n",
      "('\\n===================FOLD=', 2)\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 19s - loss: 1.1873 - acc: 0.5081 - val_loss: 7.5820 - val_acc: 0.5296\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 14s - loss: 0.7598 - acc: 0.5383 - val_loss: 7.5820 - val_acc: 0.5296\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 14s - loss: 0.6995 - acc: 0.5658 - val_loss: 7.4684 - val_acc: 0.5296\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 14s - loss: 0.6303 - acc: 0.5880 - val_loss: 3.3930 - val_acc: 0.5296\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 14s - loss: 0.5683 - acc: 0.6670 - val_loss: 4.1743 - val_acc: 0.5296\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 14s - loss: 0.5357 - acc: 0.7113 - val_loss: 0.7578 - val_acc: 0.7072\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 14s - loss: 0.4162 - acc: 0.7850 - val_loss: 0.9663 - val_acc: 0.7352\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 14s - loss: 0.3281 - acc: 0.8348 - val_loss: 0.5745 - val_acc: 0.7757\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 14s - loss: 0.4197 - acc: 0.7723 - val_loss: 1.1063 - val_acc: 0.6822\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 14s - loss: 0.4063 - acc: 0.8032 - val_loss: 0.6032 - val_acc: 0.7383\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 13s - loss: 0.4766 - acc: 0.8085 - val_loss: 1.0384 - val_acc: 0.7072\n",
      "Epoch 12/100\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.4844 - acc: 0.7744\n",
      "Epoch 00011: reducing learning rate to 0.000500000023749.\n",
      "12/12 [==============================] - 14s - loss: 0.4740 - acc: 0.7764 - val_loss: 2.7105 - val_acc: 0.5483\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 14s - loss: 0.4098 - acc: 0.7921 - val_loss: 0.9750 - val_acc: 0.6947\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 14s - loss: 0.3296 - acc: 0.8340 - val_loss: 1.5237 - val_acc: 0.6324\n",
      "Epoch 15/100\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.3138 - acc: 0.8537\n",
      "Epoch 00014: reducing learning rate to 0.000250000011874.\n",
      "12/12 [==============================] - 14s - loss: 0.3107 - acc: 0.8578 - val_loss: 0.7190 - val_acc: 0.7695\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 14s - loss: 0.3088 - acc: 0.8702 - val_loss: 0.7438 - val_acc: 0.7788\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 14s - loss: 0.2904 - acc: 0.8491 - val_loss: 0.3704 - val_acc: 0.8411\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 14s - loss: 0.2897 - acc: 0.8715 - val_loss: 0.4006 - val_acc: 0.8474\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 14s - loss: 0.2722 - acc: 0.8794 - val_loss: 0.4223 - val_acc: 0.8287\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 14s - loss: 0.4366 - acc: 0.8221 - val_loss: 0.3446 - val_acc: 0.8567\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 14s - loss: 0.2963 - acc: 0.8676 - val_loss: 0.3672 - val_acc: 0.8474\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 13s - loss: 0.2562 - acc: 0.8890 - val_loss: 0.3776 - val_acc: 0.8349\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 14s - loss: 0.2843 - acc: 0.8774 - val_loss: 0.3432 - val_acc: 0.8474\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 14s - loss: 0.2786 - acc: 0.8814 - val_loss: 0.3363 - val_acc: 0.8442\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 14s - loss: 0.3016 - acc: 0.8471 - val_loss: 0.3415 - val_acc: 0.8505\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 14s - loss: 0.2838 - acc: 0.8622 - val_loss: 0.3367 - val_acc: 0.8474\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 14s - loss: 0.2656 - acc: 0.8781 - val_loss: 0.3248 - val_acc: 0.8474\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 14s - loss: 0.2668 - acc: 0.8794 - val_loss: 0.3651 - val_acc: 0.8411\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 14s - loss: 0.2694 - acc: 0.8676 - val_loss: 0.3365 - val_acc: 0.8536\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 14s - loss: 0.2463 - acc: 0.8912 - val_loss: 0.3455 - val_acc: 0.8505\n",
      "Epoch 31/100\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.2210 - acc: 0.9155\n",
      "Epoch 00030: reducing learning rate to 0.000125000005937.\n",
      "12/12 [==============================] - 14s - loss: 0.2296 - acc: 0.9115 - val_loss: 0.3351 - val_acc: 0.8536\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 14s - loss: 0.3581 - acc: 0.8544 - val_loss: 0.3268 - val_acc: 0.8536\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 14s - loss: 0.2369 - acc: 0.8989 - val_loss: 0.3167 - val_acc: 0.8598\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 14s - loss: 0.3801 - acc: 0.8477 - val_loss: 0.3313 - val_acc: 0.8567\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 14s - loss: 0.2777 - acc: 0.8741 - val_loss: 0.3276 - val_acc: 0.8474\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 14s - loss: 0.2463 - acc: 0.8899 - val_loss: 0.3128 - val_acc: 0.8505\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 14s - loss: 0.2699 - acc: 0.8932 - val_loss: 0.3142 - val_acc: 0.8474\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 14s - loss: 0.2659 - acc: 0.8807 - val_loss: 0.3122 - val_acc: 0.8598\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 14s - loss: 0.3017 - acc: 0.8662 - val_loss: 0.3106 - val_acc: 0.8598\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 14s - loss: 0.2870 - acc: 0.8662 - val_loss: 0.3161 - val_acc: 0.8598\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 14s - loss: 0.2611 - acc: 0.8886 - val_loss: 0.3102 - val_acc: 0.8567\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 14s - loss: 0.2327 - acc: 0.8971 - val_loss: 0.3130 - val_acc: 0.8598\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 14s - loss: 0.2544 - acc: 0.8991 - val_loss: 0.3142 - val_acc: 0.8505\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 13s - loss: 0.2271 - acc: 0.9048 - val_loss: 0.3120 - val_acc: 0.8536\n",
      "Epoch 45/100\n",
      "11/12 [==========================>...] - ETA: 1s - loss: 0.2864 - acc: 0.8724\n",
      "Epoch 00044: reducing learning rate to 6.25000029686e-05.\n",
      "12/12 [==============================] - 14s - loss: 0.2829 - acc: 0.8740 - val_loss: 0.3152 - val_acc: 0.8536\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 14s - loss: 0.2398 - acc: 0.9017 - val_loss: 0.3299 - val_acc: 0.8536\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 14s - loss: 0.2295 - acc: 0.8997 - val_loss: 0.3080 - val_acc: 0.8598\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 14s - loss: 0.3718 - acc: 0.8707 - val_loss: 0.3308 - val_acc: 0.8411\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 14s - loss: 0.3837 - acc: 0.8352 - val_loss: 0.3174 - val_acc: 0.8474\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 14s - loss: 0.2620 - acc: 0.8951 - val_loss: 0.3098 - val_acc: 0.8567\n",
      "Epoch 51/100\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.2307 - acc: 0.8977\n",
      "Epoch 00050: reducing learning rate to 3.12500014843e-05.\n",
      "12/12 [==============================] - 14s - loss: 0.2376 - acc: 0.8938 - val_loss: 0.3161 - val_acc: 0.8567\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 14s - loss: 0.2665 - acc: 0.8734 - val_loss: 0.3084 - val_acc: 0.8629\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 14s - loss: 0.2373 - acc: 0.8951 - val_loss: 0.3091 - val_acc: 0.8629\n",
      "Epoch 54/100\n",
      "11/12 [==========================>...] - ETA: 1s - loss: 0.2499 - acc: 0.8935\n",
      "Epoch 00053: reducing learning rate to 1.56250007421e-05.\n",
      "12/12 [==============================] - 14s - loss: 0.2506 - acc: 0.8912 - val_loss: 0.3124 - val_acc: 0.8567\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 13s - loss: 0.2948 - acc: 0.8475 - val_loss: 0.3106 - val_acc: 0.8629\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 14s - loss: 0.2299 - acc: 0.9082 - val_loss: 0.3136 - val_acc: 0.8598\n",
      "Epoch 57/100\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.2572 - acc: 0.8681\n",
      "Epoch 00056: reducing learning rate to 7.81250037107e-06.\n",
      "12/12 [==============================] - 14s - loss: 0.2555 - acc: 0.8720 - val_loss: 0.3116 - val_acc: 0.8598\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 13s - loss: 0.3075 - acc: 0.8753 - val_loss: 0.3097 - val_acc: 0.8598\n",
      "('Train loss:', 0.2162031703922587)\n",
      "('Train accuracy:', 0.89945440374123153)\n",
      "('Test loss:', 0.30797351005478441)\n",
      "('Test accuracy:', 0.85981308411214952)\n",
      "('\\n===================FOLD=', 3)\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 17s - loss: 1.1716 - acc: 0.5147 - val_loss: 7.5820 - val_acc: 0.5296\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 14s - loss: 0.7094 - acc: 0.5692 - val_loss: 7.5820 - val_acc: 0.5296\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 14s - loss: 0.6173 - acc: 0.5927 - val_loss: 7.4510 - val_acc: 0.5296\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 14s - loss: 0.5457 - acc: 0.6880 - val_loss: 4.6434 - val_acc: 0.5576\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 14s - loss: 0.9120 - acc: 0.6266 - val_loss: 4.7430 - val_acc: 0.5296\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 13s - loss: 0.5443 - acc: 0.7010 - val_loss: 7.5053 - val_acc: 0.5296\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 14s - loss: 0.4744 - acc: 0.7647 - val_loss: 6.6810 - val_acc: 0.5296\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 14s - loss: 0.4587 - acc: 0.7646 - val_loss: 3.4952 - val_acc: 0.5296\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 14s - loss: 0.4060 - acc: 0.7981 - val_loss: 2.9010 - val_acc: 0.5296\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 14s - loss: 0.3840 - acc: 0.7993 - val_loss: 0.9738 - val_acc: 0.6947\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 14s - loss: 0.3501 - acc: 0.8283 - val_loss: 0.6293 - val_acc: 0.7352\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 14s - loss: 0.3404 - acc: 0.8157 - val_loss: 0.5282 - val_acc: 0.7882\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 14s - loss: 0.3688 - acc: 0.8499 - val_loss: 0.5967 - val_acc: 0.7259\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 14s - loss: 0.4121 - acc: 0.8066 - val_loss: 0.3445 - val_acc: 0.8536\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 14s - loss: 0.3102 - acc: 0.8551 - val_loss: 0.3430 - val_acc: 0.8598\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 14s - loss: 0.2876 - acc: 0.8682 - val_loss: 0.3179 - val_acc: 0.8505\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 14s - loss: 0.2493 - acc: 0.8984 - val_loss: 0.3378 - val_acc: 0.8785\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 14s - loss: 0.3136 - acc: 0.8439 - val_loss: 0.3002 - val_acc: 0.8629\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 14s - loss: 0.2771 - acc: 0.8748 - val_loss: 0.3072 - val_acc: 0.8536\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 14s - loss: 0.3127 - acc: 0.8386 - val_loss: 0.3377 - val_acc: 0.8411\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 14s - loss: 0.3417 - acc: 0.8157 - val_loss: 0.3796 - val_acc: 0.8380\n",
      "Epoch 22/100\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.5779 - acc: 0.7992\n",
      "Epoch 00021: reducing learning rate to 0.000500000023749.\n",
      "12/12 [==============================] - 13s - loss: 0.5356 - acc: 0.8157 - val_loss: 0.5018 - val_acc: 0.7726\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 14s - loss: 0.3129 - acc: 0.8637 - val_loss: 0.3615 - val_acc: 0.8380\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 14s - loss: 0.3219 - acc: 0.8439 - val_loss: 0.4340 - val_acc: 0.8131\n",
      "Epoch 25/100\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.3328 - acc: 0.8397\n",
      "Epoch 00024: reducing learning rate to 0.000250000011874.\n",
      "12/12 [==============================] - 14s - loss: 0.3350 - acc: 0.8393 - val_loss: 0.3702 - val_acc: 0.8505\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 14s - loss: 0.3199 - acc: 0.8558 - val_loss: 0.4033 - val_acc: 0.8131\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 14s - loss: 0.2703 - acc: 0.8846 - val_loss: 0.3048 - val_acc: 0.8692\n",
      "Epoch 28/100\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.2380 - acc: 0.9020\n",
      "Epoch 00027: reducing learning rate to 0.000125000005937.\n",
      "12/12 [==============================] - 14s - loss: 0.2387 - acc: 0.8997 - val_loss: 0.3490 - val_acc: 0.8380\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 14s - loss: 0.2494 - acc: 0.8925 - val_loss: 0.3278 - val_acc: 0.8629\n",
      "('Train loss:', 0.26471820740800117)\n",
      "('Train accuracy:', 0.88776305533904909)\n",
      "('Test loss:', 0.30015671833467633)\n",
      "('Test accuracy:', 0.86292834890965731)\n",
      "('\\n===================FOLD=', 4)\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 17s - loss: 1.7632 - acc: 0.4634 - val_loss: 7.5517 - val_acc: 0.5312\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 14s - loss: 0.7087 - acc: 0.5711 - val_loss: 7.5554 - val_acc: 0.5312\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 14s - loss: 0.6708 - acc: 0.5940 - val_loss: 7.5533 - val_acc: 0.5312\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 14s - loss: 0.6714 - acc: 0.6177 - val_loss: 4.7611 - val_acc: 0.5312\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 14s - loss: 0.5033 - acc: 0.7461 - val_loss: 0.9090 - val_acc: 0.7375\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 13s - loss: 0.5946 - acc: 0.7493 - val_loss: 2.8623 - val_acc: 0.5437\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 14s - loss: 0.4598 - acc: 0.7706 - val_loss: 1.0653 - val_acc: 0.7375\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 14s - loss: 0.4511 - acc: 0.7942 - val_loss: 0.9315 - val_acc: 0.7000\n",
      "Epoch 9/100\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.3922 - acc: 0.8104\n",
      "Epoch 00008: reducing learning rate to 0.000500000023749.\n",
      "12/12 [==============================] - 14s - loss: 0.3855 - acc: 0.8169 - val_loss: 0.9335 - val_acc: 0.7438\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 14s - loss: 0.5353 - acc: 0.7645 - val_loss: 0.6252 - val_acc: 0.7219\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 13s - loss: 0.3469 - acc: 0.8506 - val_loss: 0.4125 - val_acc: 0.7969\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 14s - loss: 0.3645 - acc: 0.8356 - val_loss: 0.4398 - val_acc: 0.8094\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 14s - loss: 0.3615 - acc: 0.8329 - val_loss: 0.6051 - val_acc: 0.7469\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 14s - loss: 0.3180 - acc: 0.8669 - val_loss: 0.6901 - val_acc: 0.7312\n",
      "Epoch 15/100\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.2968 - acc: 0.8615\n",
      "Epoch 00014: reducing learning rate to 0.000250000011874.\n",
      "12/12 [==============================] - 14s - loss: 0.2984 - acc: 0.8588 - val_loss: 0.5518 - val_acc: 0.7844\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 14s - loss: 0.3501 - acc: 0.8463 - val_loss: 0.8022 - val_acc: 0.7250\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 14s - loss: 0.3239 - acc: 0.8538 - val_loss: 0.3984 - val_acc: 0.8219\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 14s - loss: 0.2770 - acc: 0.8801 - val_loss: 0.4154 - val_acc: 0.8063\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 14s - loss: 0.3037 - acc: 0.8709 - val_loss: 0.4003 - val_acc: 0.8156\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 14s - loss: 0.2703 - acc: 0.8807 - val_loss: 0.3942 - val_acc: 0.8125\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 14s - loss: 0.2523 - acc: 0.8886 - val_loss: 0.4109 - val_acc: 0.8219\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 13s - loss: 0.3299 - acc: 0.8671 - val_loss: 0.3732 - val_acc: 0.8375\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 14s - loss: 0.2857 - acc: 0.8774 - val_loss: 0.3628 - val_acc: 0.8219\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 14s - loss: 0.3090 - acc: 0.8421 - val_loss: 0.3663 - val_acc: 0.8156\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 14s - loss: 0.2589 - acc: 0.8781 - val_loss: 0.3842 - val_acc: 0.8344\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 14s - loss: 0.2882 - acc: 0.8879 - val_loss: 0.4078 - val_acc: 0.8313\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 14s - loss: 0.2920 - acc: 0.8581 - val_loss: 0.3537 - val_acc: 0.8375\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 14s - loss: 0.2787 - acc: 0.8647 - val_loss: 0.3624 - val_acc: 0.8375\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 14s - loss: 0.2645 - acc: 0.8873 - val_loss: 0.3770 - val_acc: 0.8187\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 14s - loss: 0.2759 - acc: 0.8853 - val_loss: 0.3684 - val_acc: 0.8250\n",
      "Epoch 31/100\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.2431 - acc: 0.8906\n",
      "Epoch 00030: reducing learning rate to 0.000125000005937.\n",
      "12/12 [==============================] - 14s - loss: 0.2508 - acc: 0.8879 - val_loss: 0.3664 - val_acc: 0.8281\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 13s - loss: 0.2657 - acc: 0.8827 - val_loss: 0.3634 - val_acc: 0.8281\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 13s - loss: 0.2838 - acc: 0.8704 - val_loss: 0.3484 - val_acc: 0.8469\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 14s - loss: 0.2792 - acc: 0.8699 - val_loss: 0.3809 - val_acc: 0.8187\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 14s - loss: 0.2596 - acc: 0.8899 - val_loss: 0.3776 - val_acc: 0.8219\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 14s - loss: 0.2610 - acc: 0.8866 - val_loss: 0.3746 - val_acc: 0.8156\n",
      "Epoch 37/100\n",
      "11/12 [==========================>...] - ETA: 1s - loss: 0.3277 - acc: 0.8714\n",
      "Epoch 00036: reducing learning rate to 6.25000029686e-05.\n",
      "12/12 [==============================] - 14s - loss: 0.3150 - acc: 0.8706 - val_loss: 0.3677 - val_acc: 0.8344\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 14s - loss: 0.2830 - acc: 0.8699 - val_loss: 0.3662 - val_acc: 0.8281\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 14s - loss: 0.2291 - acc: 0.9050 - val_loss: 0.3686 - val_acc: 0.8281\n",
      "Epoch 40/100\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.2839 - acc: 0.8835\n",
      "Epoch 00039: reducing learning rate to 3.12500014843e-05.\n",
      "12/12 [==============================] - 14s - loss: 0.2805 - acc: 0.8811 - val_loss: 0.3749 - val_acc: 0.8250\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 14s - loss: 0.2409 - acc: 0.8971 - val_loss: 0.3654 - val_acc: 0.8344\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 14s - loss: 0.2388 - acc: 0.8804 - val_loss: 0.3648 - val_acc: 0.8313\n",
      "Epoch 43/100\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.2567 - acc: 0.8977\n",
      "Epoch 00042: reducing learning rate to 1.56250007421e-05.\n",
      "12/12 [==============================] - 14s - loss: 0.2500 - acc: 0.9030 - val_loss: 0.3710 - val_acc: 0.8281\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 13s - loss: 0.2154 - acc: 0.9055 - val_loss: 0.3729 - val_acc: 0.8313\n",
      "('Train loss:', 0.24413634247126237)\n",
      "('Train accuracy:', 0.90109034267912769)\n",
      "('Test loss:', 0.34838380813598635)\n",
      "('Test accuracy:', 0.84687500000000004)\n",
      "('\\n===================FOLD=', 5)\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 17s - loss: 1.6000 - acc: 0.5317 - val_loss: 7.5554 - val_acc: 0.5312\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 14s - loss: 0.7422 - acc: 0.5535 - val_loss: 7.5554 - val_acc: 0.5312\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 14s - loss: 0.6242 - acc: 0.6703 - val_loss: 7.5350 - val_acc: 0.5312\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 14s - loss: 0.6975 - acc: 0.6433 - val_loss: 7.2217 - val_acc: 0.5312\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 14s - loss: 0.5538 - acc: 0.6875 - val_loss: 6.6671 - val_acc: 0.5375\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 14s - loss: 0.4135 - acc: 0.8001 - val_loss: 5.2062 - val_acc: 0.5656\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 14s - loss: 0.3914 - acc: 0.8044 - val_loss: 4.1853 - val_acc: 0.5406\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 14s - loss: 0.3968 - acc: 0.8125 - val_loss: 0.8454 - val_acc: 0.7625\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 14s - loss: 0.3393 - acc: 0.8473 - val_loss: 1.3470 - val_acc: 0.6813\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 14s - loss: 0.3354 - acc: 0.8565 - val_loss: 0.6591 - val_acc: 0.7875\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 13s - loss: 0.3131 - acc: 0.8572 - val_loss: 0.5723 - val_acc: 0.8000\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 14s - loss: 0.3305 - acc: 0.8669 - val_loss: 0.5098 - val_acc: 0.8250\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 14s - loss: 0.3767 - acc: 0.8212 - val_loss: 0.3473 - val_acc: 0.8281\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 14s - loss: 0.3479 - acc: 0.8221 - val_loss: 0.2996 - val_acc: 0.8781\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 14s - loss: 0.3303 - acc: 0.8391 - val_loss: 0.3817 - val_acc: 0.8531\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 14s - loss: 0.2708 - acc: 0.8735 - val_loss: 0.3566 - val_acc: 0.8781\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 14s - loss: 0.3336 - acc: 0.8444 - val_loss: 0.2867 - val_acc: 0.8719\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 13s - loss: 0.4222 - acc: 0.8228 - val_loss: 0.4391 - val_acc: 0.8094\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 14s - loss: 0.3379 - acc: 0.8486 - val_loss: 0.5757 - val_acc: 0.8156\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 14s - loss: 0.2935 - acc: 0.8846 - val_loss: 0.6784 - val_acc: 0.7812\n",
      "Epoch 21/100\n",
      "11/12 [==========================>...] - ETA: 1s - loss: 0.2879 - acc: 0.8814\n",
      "Epoch 00020: reducing learning rate to 0.000500000023749.\n",
      "12/12 [==============================] - 14s - loss: 0.2969 - acc: 0.8755 - val_loss: 0.3131 - val_acc: 0.8625\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 13s - loss: 0.3515 - acc: 0.8492 - val_loss: 0.3698 - val_acc: 0.8125\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 14s - loss: 0.3126 - acc: 0.8601 - val_loss: 0.2324 - val_acc: 0.8812\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 14s - loss: 0.2843 - acc: 0.8768 - val_loss: 0.2299 - val_acc: 0.8938\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 14s - loss: 0.2750 - acc: 0.8739 - val_loss: 0.2263 - val_acc: 0.8969\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 14s - loss: 0.2641 - acc: 0.8945 - val_loss: 0.2275 - val_acc: 0.8969\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 14s - loss: 0.2598 - acc: 0.8951 - val_loss: 0.2192 - val_acc: 0.9062\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 14s - loss: 0.2511 - acc: 0.8831 - val_loss: 0.2184 - val_acc: 0.8969\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 14s - loss: 0.3051 - acc: 0.8421 - val_loss: 0.2900 - val_acc: 0.8313\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 14s - loss: 0.2939 - acc: 0.8794 - val_loss: 0.2524 - val_acc: 0.8719\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 14s - loss: 0.3282 - acc: 0.8588 - val_loss: 0.3054 - val_acc: 0.8625\n",
      "Epoch 32/100\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.4386 - acc: 0.8097\n",
      "Epoch 00031: reducing learning rate to 0.000250000011874.\n",
      "12/12 [==============================] - 14s - loss: 0.4178 - acc: 0.8153 - val_loss: 0.2562 - val_acc: 0.8812\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 13s - loss: 0.3246 - acc: 0.8550 - val_loss: 0.2398 - val_acc: 0.8938\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 14s - loss: 0.2800 - acc: 0.8605 - val_loss: 0.2384 - val_acc: 0.8969\n",
      "Epoch 35/100\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.2592 - acc: 0.8963\n",
      "Epoch 00034: reducing learning rate to 0.000125000005937.\n",
      "12/12 [==============================] - 14s - loss: 0.2582 - acc: 0.8938 - val_loss: 0.2501 - val_acc: 0.8875\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 14s - loss: 0.2647 - acc: 0.8892 - val_loss: 0.2241 - val_acc: 0.9031\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 14s - loss: 0.3039 - acc: 0.8581 - val_loss: 0.2351 - val_acc: 0.8875\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/12 [==========================>...] - ETA: 0s - loss: 0.3067 - acc: 0.8714\n",
      "Epoch 00037: reducing learning rate to 6.25000029686e-05.\n",
      "12/12 [==============================] - 14s - loss: 0.3003 - acc: 0.8732 - val_loss: 0.2299 - val_acc: 0.8969\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 14s - loss: 0.2409 - acc: 0.8863 - val_loss: 0.2258 - val_acc: 0.9000\n",
      "('Train loss:', 0.22396710691422317)\n",
      "('Train accuracy:', 0.8979750778816199)\n",
      "('Test loss:', 0.21839119493961334)\n",
      "('Test accuracy:', 0.89687499999999998)\n",
      "('\\n Train Log Loss Validation= ', 0.23703810137515618)\n",
      "(' Valid Log Loss Validation= ', 0.28040256001874009)\n"
     ]
    }
   ],
   "source": [
    "train_preds , val_preds, test_preds, train_log_loss,valid_log_loss = trainKfold(X_train, X_angle, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(file=open(\"cache/{}_tmp_results.dmp\".format(exp_name),\"wb\"), obj=[train_preds , val_preds, test_preds, train_log_loss,valid_log_loss])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds , val_preds, test_preds, train_log_loss, valid_log_loss = pickle.load(file=open(\"cache/{}_tmp_results.dmp\".format(exp_name),\"rb\"))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds  = pd.DataFrame(data={\"is_iceberg\":train_preds})\n",
    "train_preds[\"id\"]=train['id'].astype(str)\n",
    "train_preds.set_index(\"id\",inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds  = pd.DataFrame(data={\"id\":train['id'],\"is_iceberg\":val_preds})\n",
    "val_preds[\"id\"]=train['id'].astype(str)\n",
    "val_preds.set_index(\"id\",inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "012fc91e-17ff-4163-a32d-79007feba4fc",
    "_uuid": "2e7f1db4b36211939fb9650e3b721ac8db09dda2"
   },
   "outputs": [],
   "source": [
    "#Submission for each day.\n",
    "submission = pd.DataFrame()\n",
    "submission['id']=test['id']\n",
    "submission['is_iceberg']=test_preds\n",
    "submission.to_csv('subm/{}.csv'.format(exp_name), index=False)\n",
    "\n",
    "submission['id']=test['id'].astype(str)\n",
    "submission.set_index(\"id\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def submit_and_shutdown(phase, exp_name, train_preds, val_preds,test_preds, train_log_loss,valid_log_loss,shutdown=True):\n",
    "\n",
    "    lb  = 0.0\n",
    "    try:\n",
    "        submission_output = subprocess.check_output([\"kg\", \"submit\",'subm/{}.csv'.format(exp_name)])\n",
    "        lb = float(submission_output)\n",
    "\n",
    "    except Exception as e: \n",
    "        print (e)\n",
    "\n",
    "\n",
    "    update_results_h5(\"ph1\",exp_name,train_preds,val_preds,test_preds,train_log_loss,valid_log_loss,LB_score=lb)\n",
    "\n",
    "    if shutdown:\n",
    "        subprocess.call([\"sudo\", \"shutdown\", \"now\"])\n",
    "\n",
    "\n",
    "def update_results_h5(phase, exp_name, train_id, test_id, train_preds, val_preds,test_preds, train_log_loss,valid_log_loss, LB_score=0.0 ):\n",
    "    \n",
    "    train_preds  = pd.DataFrame(data={\"is_iceberg\":train_preds})\n",
    "    train_preds[\"id\"]=train_id.astype(str)\n",
    "    train_preds.set_index(\"id\",inplace=True)\n",
    "\n",
    "    \n",
    "    \n",
    "    val_preds  = pd.DataFrame(data={\"id\":train['id'],\"is_iceberg\":val_preds})\n",
    "    val_preds[\"id\"]=train_id.astype(str)\n",
    "    val_preds.set_index(\"id\",inplace=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    submission = pd.DataFrame()\n",
    "    submission['id']=test_id\n",
    "    submission['is_iceberg']=test_preds\n",
    "    submission.to_csv('subm/{}.csv'.format(exp_name), index=False)\n",
    "\n",
    "    submission['id']=test['id'].astype(str)\n",
    "    submission.set_index(\"id\",inplace=True)\n",
    "\n",
    "\n",
    "    \n",
    "    train_preds.to_hdf('data/results.h5',\"/{}/train/{}\".format(phase,exp_name))\n",
    "    val_preds.to_hdf('data/results.h5',\"/{}/valid/{}\".format(phase,exp_name))\n",
    "    submission.to_hdf('data/results.h5',\"/{}/test/{}\".format(phase,exp_name))\n",
    "\n",
    "    \n",
    "#     store = pd.HDFStore('data/results.h5')\n",
    "\n",
    "#     store.append(\"/summary\",pd.DataFrame(data={\"phase\":[phase],\n",
    "#                                                \"exp\":[exp_name],\n",
    "#                                                \"train_log_loss\":[train_log_loss],\n",
    "#                                                \"val_log_loss\":[valid_log_loss], \n",
    "#                                                \"LB\":[LB_score] }) )  \n",
    "\n",
    "#     store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit_and_shutdown(\"ph1\",exp_name,train_preds,val_preds,submission,train_log_loss,valid_log_loss,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       dfd5f913\n",
       "1       e25388fd\n",
       "2       58b2aaa0\n",
       "3       4cfc3a18\n",
       "4       271f93f4\n",
       "5       b51d18b5\n",
       "6       31da1a04\n",
       "7       56929c16\n",
       "8       525ab75c\n",
       "9       192f56eb\n",
       "10      3aac67cd\n",
       "11      161a6860\n",
       "12      3c794f0c\n",
       "13      86730f0d\n",
       "14      e356f7a3\n",
       "15      87592c38\n",
       "16      1c18a39e\n",
       "17      a210f335\n",
       "18      958d155f\n",
       "19      6d81d201\n",
       "20      75126706\n",
       "21      112a6cfa\n",
       "22      a29662a4\n",
       "23      bd1a1bdf\n",
       "24      31e37d93\n",
       "25      76b8d446\n",
       "26      958d42a8\n",
       "27      70830858\n",
       "28      faf2c49e\n",
       "29      02314c59\n",
       "          ...   \n",
       "1574    84fe7f94\n",
       "1575    04e6f331\n",
       "1576    92c90853\n",
       "1577    660a98a7\n",
       "1578    89670962\n",
       "1579    9d586019\n",
       "1580    5f49ea3b\n",
       "1581    968e1414\n",
       "1582    389d7eaf\n",
       "1583    65ca9e76\n",
       "1584    a09cae27\n",
       "1585    00c5b3e0\n",
       "1586    7f9df2b0\n",
       "1587    a2303efc\n",
       "1588    cb62e5cb\n",
       "1589    9ff1e0f0\n",
       "1590    39fd995a\n",
       "1591    544d0681\n",
       "1592    cb0319fc\n",
       "1593    d86deb2b\n",
       "1594    cdee905a\n",
       "1595    2539742b\n",
       "1596    2ea3c9f1\n",
       "1597    9cadda28\n",
       "1598    8376a077\n",
       "1599    04e11240\n",
       "1600    c7d6f6f8\n",
       "1601    bba1a0f1\n",
       "1602    7f66bb44\n",
       "1603    9d8f326c\n",
       "Name: id, Length: 1604, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"id\"].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_results_h5(\"ph1\",exp_name,train[\"id\"], test[\"id\"], \n",
    "                  train_preds,val_preds,test_preds,\n",
    "                  train_log_loss,valid_log_loss,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = pd.HDFStore('data/results.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.80484443],\n",
       "       [ 0.80484443,  1.        ]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(store.select(\"/ph1/valid/_5fold_baseline\").values.ravel(), store.select(\"/ph1/train/_5fold_baseline\").values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.remove(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/summary',\n",
       " '/ph1/test/_5fold_baseline',\n",
       " '/ph1/test/_5fold_fcn',\n",
       " '/ph1/train/_5fold_baseline',\n",
       " '/ph1/train/_5fold_fcn',\n",
       " '/ph1/valid/_5fold_baseline',\n",
       " '/ph1/valid/_5fold_fcn']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LB</th>\n",
       "      <th>exp</th>\n",
       "      <th>phase</th>\n",
       "      <th>train_log_loss</th>\n",
       "      <th>val_log_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.318</td>\n",
       "      <td>_5fold_baseline</td>\n",
       "      <td>ph1</td>\n",
       "      <td>0.305983</td>\n",
       "      <td>0.385856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>_5fold_fcn</td>\n",
       "      <td>ph1</td>\n",
       "      <td>0.237038</td>\n",
       "      <td>0.280403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>_5fold_fcn</td>\n",
       "      <td>ph1</td>\n",
       "      <td>0.237038</td>\n",
       "      <td>0.280403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      LB              exp phase  train_log_loss  val_log_loss\n",
       "0  0.318  _5fold_baseline   ph1        0.305983      0.385856\n",
       "0  0.000       _5fold_fcn   ph1        0.237038      0.280403\n",
       "0  0.000       _5fold_fcn   ph1        0.237038      0.280403"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.get('/summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark3cv = pd.read_csv(\"subm/sub_benchmark.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark3cv.set_index('id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_iceberg_3cv</th>\n",
       "      <th>is_iceberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_iceberg_3cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg</th>\n",
       "      <td>0.975071</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                is_iceberg_3cv  is_iceberg\n",
       "is_iceberg_3cv        1.000000    0.975071\n",
       "is_iceberg            0.975071    1.000000"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark3cv.join(store.get(\"/ph1/test/_5fold_baseline\"),lsuffix=\"_3cv\").corr()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
