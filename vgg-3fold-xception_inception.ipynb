{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "7922e149-72fa-48cd-a545-b70bddb40d28",
    "_uuid": "9341f2516086ca38bca96e06a9dbfc39f813a95a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import utils \n",
    "\n",
    "from utils import *\n",
    "\n",
    "from keras.applications import Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = 10, 10\n",
    "%matplotlib inline\n",
    "exp_name = \"_3f_xception\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "9d5839b6-f7fb-426d-b05f-cf2dba9313a8",
    "_uuid": "d375d4f754ad7fb77db2142c7c075b4ad4168390"
   },
   "outputs": [],
   "source": [
    "train = pd.read_json(\"data/input/train.json\")\n",
    "target_train=train['is_iceberg']\n",
    "test = pd.read_json(\"data/input/test.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['inc_angle']=pd.to_numeric(test['inc_angle'], errors='coerce')\n",
    "train['inc_angle']=pd.to_numeric(train['inc_angle'], errors='coerce')#We have only 133 NAs.\n",
    "train['inc_angle']=train['inc_angle'].fillna(method='pad')\n",
    "X_angle=train['inc_angle']\n",
    "X_test_angle=test['inc_angle']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Generate the training data\n",
    "X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\n",
    "X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\n",
    "X_band_3=(X_band_1+X_band_2)/2\n",
    "#X_band_3=np.array([np.full((75, 75), angel).astype(np.float32) for angel in train[\"inc_angle\"]])\n",
    "X_train = np.concatenate([X_band_1[:, :, :, np.newaxis]\n",
    "                          , X_band_2[:, :, :, np.newaxis]\n",
    "                         , X_band_3[:, :, :, np.newaxis]], axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "X_band_test_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_1\"]])\n",
    "X_band_test_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_2\"]])\n",
    "X_band_test_3=(X_band_test_1+X_band_test_2)/2\n",
    "#X_band_test_3=np.array([np.full((75, 75), angel).astype(np.float32) for angel in test[\"inc_angle\"]])\n",
    "X_test = np.concatenate([X_band_test_1[:, :, :, np.newaxis]\n",
    "                          , X_band_test_2[:, :, :, np.newaxis]\n",
    "                         , X_band_test_3[:, :, :, np.newaxis]], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "batch_size=64\n",
    "# Define the image transformations here\n",
    "gen = ImageDataGenerator(horizontal_flip = True,\n",
    "                         vertical_flip = True,\n",
    "                         width_shift_range = 0.,\n",
    "                         height_shift_range = 0.,\n",
    "                         channel_shift_range=0,\n",
    "                         zoom_range = 0.2,\n",
    "                         rotation_range = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Here is the function that merges our two generators\n",
    "# We use the exact same generator with the same random seed for both the y and angle arrays\n",
    "def gen_flow_for_two_inputs(X1, X2, y):\n",
    "    genX1 = gen.flow(X1,y,  batch_size=batch_size,seed=55)\n",
    "    genX2 = gen.flow(X1,X2, batch_size=batch_size,seed=55)\n",
    "    while True:\n",
    "            X1i = genX1.next()\n",
    "            X2i = genX2.next()\n",
    "            #Assert arrays are equal - this was for peace of mind, but slows down training\n",
    "            #np.testing.assert_array_equal(X1i[0],X2i[0])\n",
    "            yield [X1i[0], X2i[1]], X1i[1]\n",
    "\n",
    "# Finally create generator\n",
    "def get_callbacks(filepath, patience=5):\n",
    "    es = EarlyStopping('val_loss', patience=5, mode=\"min\")\n",
    "    msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "#     lrplateu = ReduceLROnPlateau(monitor='val_loss',  patience=2, verbose=1, factor=0.5, min_lr=1e-6)\n",
    "\n",
    "    return [es, msave]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input size must be at least 139x139; got `input_shape=(75, 75, 3)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-215383e7e152>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m InceptionV3(weights='imagenet', include_top=False, \n\u001b[0;32m----> 2\u001b[0;31m                  input_shape=X_train.shape[1:], classes=1).summary()\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/applications/inception_v3.pyc\u001b[0m in \u001b[0;36mInceptionV3\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mrequire_flatten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         weights=weights)\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/applications/imagenet_utils.pyc\u001b[0m in \u001b[0;36m_obtain_input_shape\u001b[0;34m(input_shape, default_size, min_size, data_format, require_flatten, weights)\u001b[0m\n\u001b[1;32m    162\u001b[0m                     raise ValueError('Input size must be at least ' +\n\u001b[1;32m    163\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'x'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'; got '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                                      '`input_shape=' + str(input_shape) + '`')\n\u001b[0m\u001b[1;32m    165\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrequire_flatten\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input size must be at least 139x139; got `input_shape=(75, 75, 3)`"
     ]
    }
   ],
   "source": [
    "InceptionV3(weights='imagenet', include_top=False, \n",
    "                 input_shape=X_train.shape[1:], classes=1).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel():\n",
    "    input_2 = Input(shape=[1], name=\"angle\")\n",
    "    angle_layer = Dense(1, )(input_2)\n",
    "    base_model = Xception(weights='imagenet', include_top=False, \n",
    "                 input_shape=X_train.shape[1:], classes=1)\n",
    "    x = base_model.get_layer('block14_sepconv2_act').output\n",
    "    \n",
    "\n",
    "    x = Flatten()(x)\n",
    "    merge_one = concatenate([x, angle_layer])\n",
    "    merge_one = Dense(512, activation='relu', name='fc2')(merge_one)\n",
    "    merge_one = Dropout(0.3)(merge_one)\n",
    "    merge_one = Dense(512, activation='relu', name='fc3')(merge_one)\n",
    "    merge_one = Dropout(0.3)(merge_one)\n",
    "    \n",
    "    predictions = Dense(1, activation='sigmoid')(merge_one)\n",
    "    \n",
    "    model = Model(input=[base_model.input, input_2], output=predictions)\n",
    "    \n",
    "    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "067f3dd7-3dcf-4b71-857d-e00b4afbd06e",
    "_uuid": "af8be6ce23dba815bbde23fd7e196eb54ae7c4e1"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Using K-fold Cross Validation with Data Augmentation.\n",
    "def trainKfold(X_train, X_angle, X_test):\n",
    "    K=3\n",
    "    folds = list(StratifiedKFold(n_splits=K, shuffle=True, random_state=17).split(X_train, target_train))\n",
    "    y_test_pred_log = 0\n",
    "    y_train_pred_log=0\n",
    "    y_valid_pred_log = 0.0*target_train\n",
    "    \n",
    "    \n",
    "    for j, (train_idx, test_idx) in enumerate(folds):\n",
    "        print('\\n===================FOLD=',j+1)\n",
    "        X_train_cv = X_train[train_idx]\n",
    "        y_train_cv = target_train[train_idx]\n",
    "        X_holdout = X_train[test_idx]\n",
    "        Y_holdout= target_train[test_idx]\n",
    "        \n",
    "        #Angle\n",
    "        X_angle_cv=X_angle[train_idx]\n",
    "        X_angle_hold=X_angle[test_idx]\n",
    "\n",
    "        #define file path and get callbacks\n",
    "        file_path = \"weights/{}_{}.hdf5\".format(exp_name,j+1)\n",
    "        callbacks = get_callbacks(filepath=file_path, patience=5)\n",
    "        gen_flow = gen_flow_for_two_inputs(X_train_cv, X_angle_cv, y_train_cv)\n",
    "        \n",
    "        model= getModel()\n",
    "        model.fit_generator(\n",
    "                gen_flow,\n",
    "                steps_per_epoch=24,\n",
    "                epochs=100,\n",
    "                shuffle=True,\n",
    "                verbose=1,\n",
    "                validation_data=([X_holdout,X_angle_hold], Y_holdout),\n",
    "                callbacks=callbacks)\n",
    "\n",
    "        #Getting the Best Model\n",
    "        model.load_weights(filepath=file_path)\n",
    "        #Getting Training Score\n",
    "        score = model.evaluate([X_train_cv,X_angle_cv], y_train_cv, verbose=0)\n",
    "        print('Train loss:', score[0])\n",
    "        print('Train accuracy:', score[1])\n",
    "        \n",
    "        #Getting Test Score\n",
    "        score = model.evaluate([X_holdout,X_angle_hold], Y_holdout, verbose=0)\n",
    "        print('Test loss:', score[0])\n",
    "        print('Test accuracy:', score[1])\n",
    "\n",
    "        #Getting validation Score.\n",
    "        pred_valid=model.predict([X_holdout,X_angle_hold])\n",
    "        y_valid_pred_log[test_idx] = pred_valid.reshape(pred_valid.shape[0])\n",
    "\n",
    "        #Getting Test Scores\n",
    "\n",
    "        temp_test=model.predict([X_test, X_test_angle])\n",
    "        y_test_pred_log+=temp_test.reshape(temp_test.shape[0])\n",
    "        \n",
    "\n",
    "\n",
    "        #Getting Train Scores\n",
    "        temp_train=model.predict([X_train, X_angle])\n",
    "        y_train_pred_log+=temp_train.reshape(temp_train.shape[0])\n",
    "\n",
    "    y_test_pred_log=y_test_pred_log/K\n",
    "    y_train_pred_log=y_train_pred_log/K\n",
    "\n",
    "    \n",
    "    train_log_loss = log_loss(target_train, y_train_pred_log) \n",
    "    valid_log_loss = log_loss(target_train, y_valid_pred_log)\n",
    "    \n",
    "    print('\\n Train Log Loss Validation= ',train_log_loss)\n",
    "    print(' Valid Log Loss Validation= ',valid_log_loss)\n",
    "    \n",
    "    \n",
    "    return y_train_pred_log, y_valid_pred_log, y_test_pred_log, train_log_loss, valid_log_loss\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_TTA_preds(exp_name):\n",
    "\n",
    "    K=3\n",
    "    y_test_pred_log = 0\n",
    "    \n",
    "    \n",
    "\n",
    "    def gen_flow_for_two_inputs_test(test_gen, X1, X2):\n",
    "        genX2 = test_gen.flow(X1,X2, batch_size=8,shuffle=False)\n",
    "        while True:\n",
    "                X2i = genX2.next()\n",
    "                yield [X2i[0], X2i[1]]\n",
    "\n",
    "    partials = []\n",
    "    \n",
    "    \n",
    "    for j in range(K):\n",
    "        print('\\n===================FOLD=',j+1)\n",
    "        \n",
    "        model= getModel()\n",
    "\n",
    "        #Getting the Best Model\n",
    "        model.load_weights(\"weights/{}_{}.hdf5\".format(exp_name,j+1))\n",
    "        #Getting Training Score\n",
    "\n",
    "        \n",
    "        test_gen = ImageDataGenerator(horizontal_flip = True,\n",
    "                                      vertical_flip = True, \n",
    "                                      width_shift_range = 0.,  \n",
    "                                      height_shift_range = 0.,      \n",
    "                                      channel_shift_range=0,        \n",
    "                                      zoom_range = 0.2,         \n",
    "                                      rotation_range = 10)   \n",
    "\n",
    "\n",
    "        preds = np.zeros((test.shape[0],1)).astype(np.float32) \n",
    "\n",
    "        num_aug = 5\n",
    "        for i in range(num_aug):\n",
    "            gen_flow_test = gen_flow_for_two_inputs_test(test_gen, X_test, X_test_angle)\n",
    "            preds += model.predict_generator(gen_flow_test,steps=test.shape[0]/8, verbose=1).reshape(-1,1)\n",
    "\n",
    "\n",
    "        partials.append(preds/num_aug)    \n",
    "        temp_test=preds/num_aug\n",
    "        y_test_pred_log+=temp_test.reshape(temp_test.shape[0])                           \n",
    "                           \n",
    "\n",
    "    y_test_pred_log=y_test_pred_log/K\n",
    "\n",
    "\n",
    "    \n",
    "    return y_test_pred_log, partials\n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\n===================FOLD=', 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:18: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=[<tf.Tenso...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1053/1053 [==============================] - 28s    \n",
      "1053/1053 [==============================] - 27s    \n",
      "1053/1053 [==============================] - 28s    \n",
      "1053/1053 [==============================] - 28s    \n",
      "1053/1053 [==============================] - 28s    \n",
      "('\\n===================FOLD=', 2)\n",
      "1053/1053 [==============================] - 28s    \n",
      "1053/1053 [==============================] - 28s    \n",
      "1053/1053 [==============================] - 28s    \n",
      "1053/1053 [==============================] - 28s    \n",
      "1053/1053 [==============================] - 28s    \n",
      "('\\n===================FOLD=', 3)\n",
      "1053/1053 [==============================] - 28s    \n",
      "1053/1053 [==============================] - 28s    \n",
      "1053/1053 [==============================] - 28s    \n",
      "1053/1053 [==============================] - 28s    \n",
      "1053/1053 [==============================] - 28s    \n"
     ]
    }
   ],
   "source": [
    "# tta_preds_3fold_baseline,partials = make_TTA_preds(\"_3fold_baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "ea82458f-f41c-4abb-87aa-0dfc7a447969",
    "_uuid": "d462c689ee61d4c1cdcee42c7ded6c7c31c9cddc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\n===================FOLD=', 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:18: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=[<tf.Tenso...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "24/24 [==============================] - 21s - loss: 0.6886 - acc: 0.5565 - val_loss: 0.8945 - val_acc: 0.5308\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 9s - loss: 0.6071 - acc: 0.6322 - val_loss: 0.9288 - val_acc: 0.5327\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 11s - loss: 0.5684 - acc: 0.6876 - val_loss: 0.6342 - val_acc: 0.6056\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 11s - loss: 0.5091 - acc: 0.7360 - val_loss: 0.5761 - val_acc: 0.6729\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 11s - loss: 0.4847 - acc: 0.7497 - val_loss: 0.5523 - val_acc: 0.6953\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 11s - loss: 0.4593 - acc: 0.7640 - val_loss: 0.4901 - val_acc: 0.7346\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 11s - loss: 0.4078 - acc: 0.8162 - val_loss: 0.4522 - val_acc: 0.7551\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 11s - loss: 0.3838 - acc: 0.8254 - val_loss: 0.4040 - val_acc: 0.7794\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 11s - loss: 0.3620 - acc: 0.8348 - val_loss: 0.3938 - val_acc: 0.8224\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 11s - loss: 0.3598 - acc: 0.8230 - val_loss: 0.3628 - val_acc: 0.8131\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 11s - loss: 0.3324 - acc: 0.8400 - val_loss: 0.3186 - val_acc: 0.8579\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 11s - loss: 0.3274 - acc: 0.8477 - val_loss: 0.3000 - val_acc: 0.8542\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 11s - loss: 0.3104 - acc: 0.8610 - val_loss: 0.2891 - val_acc: 0.8692\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 11s - loss: 0.2930 - acc: 0.8741 - val_loss: 0.2870 - val_acc: 0.8673\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 11s - loss: 0.2772 - acc: 0.8756 - val_loss: 0.2748 - val_acc: 0.8879\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 11s - loss: 0.2834 - acc: 0.8679 - val_loss: 0.2670 - val_acc: 0.8916\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 11s - loss: 0.2729 - acc: 0.8798 - val_loss: 0.2667 - val_acc: 0.8935\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 11s - loss: 0.2649 - acc: 0.8898 - val_loss: 0.2642 - val_acc: 0.8822\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 9s - loss: 0.2650 - acc: 0.8840 - val_loss: 0.2724 - val_acc: 0.8972\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 11s - loss: 0.2808 - acc: 0.8724 - val_loss: 0.2473 - val_acc: 0.8953\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 9s - loss: 0.2390 - acc: 0.8938 - val_loss: 0.2497 - val_acc: 0.9009\n",
      "Epoch 22/100\n",
      "24/24 [==============================] - 11s - loss: 0.2859 - acc: 0.8751 - val_loss: 0.2461 - val_acc: 0.9047\n",
      "Epoch 23/100\n",
      "24/24 [==============================] - 9s - loss: 0.2454 - acc: 0.8904 - val_loss: 0.2502 - val_acc: 0.8953\n",
      "Epoch 24/100\n",
      "24/24 [==============================] - 9s - loss: 0.2361 - acc: 0.8945 - val_loss: 0.2535 - val_acc: 0.8935\n",
      "Epoch 25/100\n",
      "24/24 [==============================] - 9s - loss: 0.2440 - acc: 0.8949 - val_loss: 0.2540 - val_acc: 0.8991\n",
      "Epoch 26/100\n",
      "24/24 [==============================] - 9s - loss: 0.2462 - acc: 0.8915 - val_loss: 0.2493 - val_acc: 0.8897\n",
      "Epoch 27/100\n",
      "24/24 [==============================] - 11s - loss: 0.2376 - acc: 0.8969 - val_loss: 0.2444 - val_acc: 0.9009\n",
      "Epoch 28/100\n",
      "24/24 [==============================] - 9s - loss: 0.2235 - acc: 0.9016 - val_loss: 0.2496 - val_acc: 0.8916\n",
      "Epoch 29/100\n",
      "24/24 [==============================] - 9s - loss: 0.2245 - acc: 0.9037 - val_loss: 0.2480 - val_acc: 0.8972\n",
      "Epoch 30/100\n",
      "24/24 [==============================] - 9s - loss: 0.2334 - acc: 0.8970 - val_loss: 0.2493 - val_acc: 0.9028\n",
      "Epoch 31/100\n",
      "24/24 [==============================] - 9s - loss: 0.2201 - acc: 0.9118 - val_loss: 0.2503 - val_acc: 0.8953\n",
      "Epoch 32/100\n",
      "24/24 [==============================] - 9s - loss: 0.2371 - acc: 0.9020 - val_loss: 0.2475 - val_acc: 0.8953\n",
      "Epoch 33/100\n",
      "24/24 [==============================] - 9s - loss: 0.2180 - acc: 0.9118 - val_loss: 0.2598 - val_acc: 0.8953\n",
      "('Train loss:', 0.17722946935802894)\n",
      "('Train accuracy:', 0.92235734409210945)\n",
      "('Test loss:', 0.24437953111167265)\n",
      "('Test accuracy:', 0.90093457955066292)\n",
      "('\\n===================FOLD=', 2)\n",
      "Epoch 1/100\n",
      "24/24 [==============================] - 25s - loss: 0.6810 - acc: 0.5435 - val_loss: 0.7198 - val_acc: 0.5196\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 9s - loss: 0.6012 - acc: 0.6628 - val_loss: 0.8891 - val_acc: 0.5308\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 11s - loss: 0.5620 - acc: 0.6765 - val_loss: 0.6678 - val_acc: 0.5776\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 9s - loss: 0.4946 - acc: 0.7463 - val_loss: 0.6989 - val_acc: 0.5514\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 11s - loss: 0.4752 - acc: 0.7477 - val_loss: 0.6397 - val_acc: 0.6224\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 11s - loss: 0.4280 - acc: 0.7979 - val_loss: 0.5813 - val_acc: 0.6729\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 11s - loss: 0.3970 - acc: 0.8014 - val_loss: 0.5551 - val_acc: 0.6991\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 11s - loss: 0.3815 - acc: 0.8143 - val_loss: 0.4257 - val_acc: 0.7850\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 11s - loss: 0.3390 - acc: 0.8405 - val_loss: 0.3669 - val_acc: 0.8374\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 11s - loss: 0.3335 - acc: 0.8465 - val_loss: 0.3362 - val_acc: 0.8636\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 11s - loss: 0.3170 - acc: 0.8657 - val_loss: 0.3137 - val_acc: 0.8542\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 11s - loss: 0.3002 - acc: 0.8606 - val_loss: 0.3027 - val_acc: 0.8542\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 9s - loss: 0.2909 - acc: 0.8687 - val_loss: 0.3153 - val_acc: 0.8654\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 9s - loss: 0.2920 - acc: 0.8672 - val_loss: 0.3342 - val_acc: 0.8505\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 11s - loss: 0.2869 - acc: 0.8793 - val_loss: 0.2922 - val_acc: 0.8617\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 9s - loss: 0.2598 - acc: 0.8832 - val_loss: 0.3017 - val_acc: 0.8542\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 9s - loss: 0.2622 - acc: 0.8909 - val_loss: 0.2933 - val_acc: 0.8636\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 9s - loss: 0.2546 - acc: 0.8856 - val_loss: 0.2929 - val_acc: 0.8729\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 11s - loss: 0.2541 - acc: 0.8960 - val_loss: 0.2861 - val_acc: 0.8673\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 11s - loss: 0.2479 - acc: 0.8957 - val_loss: 0.2776 - val_acc: 0.8729\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 9s - loss: 0.2242 - acc: 0.9040 - val_loss: 0.2923 - val_acc: 0.8804\n",
      "Epoch 22/100\n",
      "24/24 [==============================] - 9s - loss: 0.2768 - acc: 0.8824 - val_loss: 0.2819 - val_acc: 0.8841\n",
      "Epoch 23/100\n",
      "24/24 [==============================] - 9s - loss: 0.2409 - acc: 0.8984 - val_loss: 0.2840 - val_acc: 0.8879\n",
      "Epoch 24/100\n",
      "24/24 [==============================] - 9s - loss: 0.2277 - acc: 0.9063 - val_loss: 0.2954 - val_acc: 0.8748\n",
      "Epoch 25/100\n",
      "24/24 [==============================] - 9s - loss: 0.2323 - acc: 0.9055 - val_loss: 0.2873 - val_acc: 0.8729\n",
      "Epoch 26/100\n",
      "24/24 [==============================] - 9s - loss: 0.2267 - acc: 0.9042 - val_loss: 0.3234 - val_acc: 0.8561\n",
      "('Train loss:', 0.20080528424319205)\n",
      "('Train accuracy:', 0.91300280719744586)\n",
      "('Test loss:', 0.27757560360097439)\n",
      "('Test accuracy:', 0.87289719670732446)\n",
      "('\\n===================FOLD=', 3)\n",
      "Epoch 1/100\n",
      "24/24 [==============================] - 29s - loss: 0.6870 - acc: 0.5546 - val_loss: 1.0518 - val_acc: 0.5300\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 11s - loss: 0.6215 - acc: 0.6221 - val_loss: 0.8693 - val_acc: 0.5150\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 11s - loss: 0.5824 - acc: 0.6602 - val_loss: 0.6338 - val_acc: 0.6199\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 11s - loss: 0.5481 - acc: 0.6805 - val_loss: 0.6221 - val_acc: 0.6273\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 11s - loss: 0.5057 - acc: 0.7362 - val_loss: 0.5899 - val_acc: 0.6704\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 9s - loss: 0.4764 - acc: 0.7430 - val_loss: 0.6810 - val_acc: 0.6330\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 11s - loss: 0.4604 - acc: 0.7730 - val_loss: 0.5439 - val_acc: 0.6985\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 9s - loss: 0.4362 - acc: 0.7930 - val_loss: 0.5488 - val_acc: 0.7097\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 11s - loss: 0.3761 - acc: 0.8237 - val_loss: 0.3902 - val_acc: 0.8034\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 11s - loss: 0.3758 - acc: 0.8262 - val_loss: 0.3461 - val_acc: 0.8352\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 9s - loss: 0.3487 - acc: 0.8412 - val_loss: 0.3681 - val_acc: 0.8184\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 11s - loss: 0.3346 - acc: 0.8482 - val_loss: 0.2975 - val_acc: 0.8652\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 11s - loss: 0.3189 - acc: 0.8513 - val_loss: 0.2741 - val_acc: 0.8858\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 11s - loss: 0.3158 - acc: 0.8631 - val_loss: 0.2664 - val_acc: 0.8764\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 11s - loss: 0.3221 - acc: 0.8592 - val_loss: 0.2599 - val_acc: 0.8876\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 11s - loss: 0.3199 - acc: 0.8556 - val_loss: 0.2543 - val_acc: 0.8858\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 9s - loss: 0.2786 - acc: 0.8779 - val_loss: 0.2595 - val_acc: 0.8820\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 9s - loss: 0.2758 - acc: 0.8809 - val_loss: 0.2772 - val_acc: 0.8764\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 11s - loss: 0.2882 - acc: 0.8705 - val_loss: 0.2411 - val_acc: 0.8914\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 9s - loss: 0.2631 - acc: 0.8917 - val_loss: 0.2841 - val_acc: 0.8670\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 9s - loss: 0.2562 - acc: 0.8899 - val_loss: 0.2850 - val_acc: 0.8670\n",
      "Epoch 22/100\n",
      "24/24 [==============================] - 9s - loss: 0.2766 - acc: 0.8846 - val_loss: 0.2446 - val_acc: 0.8801\n",
      "Epoch 23/100\n",
      "24/24 [==============================] - 9s - loss: 0.2711 - acc: 0.8775 - val_loss: 0.2555 - val_acc: 0.8820\n",
      "Epoch 24/100\n",
      "24/24 [==============================] - 9s - loss: 0.2671 - acc: 0.8861 - val_loss: 0.2482 - val_acc: 0.8783\n",
      "Epoch 25/100\n",
      "24/24 [==============================] - 9s - loss: 0.2333 - acc: 0.9034 - val_loss: 0.2465 - val_acc: 0.8895\n",
      "('Train loss:', 0.218010585720294)\n",
      "('Train accuracy:', 0.90093457988489456)\n",
      "('Test loss:', 0.24113444308663129)\n",
      "('Test accuracy:', 0.89138576689730864)\n",
      "('\\n Train Log Loss Validation= ', 0.20352725006922978)\n",
      "(' Valid Log Loss Validation= ', 0.25437143984983279)\n"
     ]
    }
   ],
   "source": [
    "train_preds , val_preds, test_preds, train_log_loss,valid_log_loss = trainKfold(X_train, X_angle, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(file=open(\"cache/{}_tmp_results.dmp\".format(exp_name),\"wb\"), obj=[train_preds , val_preds, test_preds, train_log_loss,valid_log_loss])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds , val_preds, test_preds, train_log_loss, valid_log_loss = pickle.load(file=open(\"tmp_results.dmp\",\"rb\"))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def update_results_h5(phase, exp_name, train_id, test_id, train_preds, val_preds,test_preds, train_log_loss,valid_log_loss, LB_score=0.0):\n",
    "\t\t\n",
    "\t\ttrain_preds  = pd.DataFrame(data={\"is_iceberg\":train_preds})\n",
    "\t\ttrain_preds[\"id\"]=train_id.astype(str)\n",
    "\t\ttrain_preds.set_index(\"id\",inplace=True)\n",
    "\n",
    "\t\t\n",
    "\t\t\n",
    "\t\tval_preds  = pd.DataFrame(data={\"id\":train['id'],\"is_iceberg\":val_preds})\n",
    "\t\tval_preds[\"id\"]=train_id.astype(str)\n",
    "\t\tval_preds.set_index(\"id\",inplace=True)\n",
    "\t\t\n",
    "\t\t\n",
    "\t\t\n",
    "\t\tsubmission = pd.DataFrame()\n",
    "\t\tsubmission['id']=test_id\n",
    "\t\tsubmission['is_iceberg']=test_preds\n",
    "\t\tsubmission.to_csv('subm/{}.csv'.format(exp_name), index=False)\n",
    "\n",
    "\t\tsubmission['id']=test['id'].astype(str)\n",
    "\t\tsubmission.set_index(\"id\",inplace=True)\n",
    "\n",
    "\n",
    "\t\t\n",
    "\t\ttrain_preds.to_hdf('data/results.h5',\"/{}/train/{}\".format(phase,exp_name))\n",
    "\t\tval_preds.to_hdf('data/results.h5',\"/{}/valid/{}\".format(phase,exp_name))\n",
    "\t\tsubmission.to_hdf('data/results.h5',\"/{}/test/{}\".format(phase,exp_name))\n",
    "\n",
    "\n",
    "\n",
    "\t\t\n",
    "\n",
    "\t\tstore = pd.HDFStore('data/results.h5')\n",
    "\n",
    "\t\tstore.append(\"/summary\",pd.DataFrame(data={\"phase\":[phase],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t \"exp\":[exp_name],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t \"train_log_loss\":[train_log_loss],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t \"val_log_loss\":[valid_log_loss], \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t \"LB\":[LB_score] }) )  \n",
    "\n",
    "\t\tstore.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_results_h5(\"ph1\", exp_name, train[\"id\"], test[\"id\"], \n",
    "                  train_preds, val_preds,test_preds, train_log_loss,valid_log_loss, LB_score=0.0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds  = pd.DataFrame(data={\"is_iceberg\":train_preds})\n",
    "train_preds[\"id\"]=train['id'].astype(str)\n",
    "train_preds.set_index(\"id\",inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds  = pd.DataFrame(data={\"id\":train['id'],\"is_iceberg\":val_preds})\n",
    "val_preds[\"id\"]=train['id'].astype(str)\n",
    "val_preds.set_index(\"id\",inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "012fc91e-17ff-4163-a32d-79007feba4fc",
    "_uuid": "2e7f1db4b36211939fb9650e3b721ac8db09dda2"
   },
   "outputs": [],
   "source": [
    "#Submission for each day.\n",
    "submission = pd.DataFrame()\n",
    "submission['id']=test['id'].astype(str)\n",
    "submission['is_iceberg']= tta_preds_3fold_baseline\n",
    "submission.to_csv('subm/{}.csv'.format(\"_3f_tta\"), index=False)\n",
    "\n",
    "submission.set_index(\"id\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def submit_and_update1(phase, exp_name, train_preds, val_preds,test_preds, train_log_loss,valid_log_loss):\n",
    "\n",
    "#     lb  = 0.0\n",
    "#     try:\n",
    "#         submission_output = subprocess.check_output([\"kg\", \"submit\",'subm/{}.csv'.format(exp_name)])\n",
    "#         lb = float(submission_output)\n",
    "\n",
    "#     except:\n",
    "#         print (submission_output)\n",
    "\n",
    "\n",
    "    update_results_h5(phase,exp_name,train_preds,val_preds,test_preds,train_log_loss,valid_log_loss,LB_score=lb)\n",
    "\n",
    "#     subprocess.call([\"sudo\", \"shutdown\", \"now\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_results_h5(phase, exp_name, train_preds, val_preds,test_preds, train_log_loss,valid_log_loss, LB_score=0.0 ):\n",
    "        store = pd.HDFStore('data/results.h5')\n",
    "        store.append(\"/{}/train/{}\".format(phase,exp_name),train_preds )\n",
    "        store.append(\"/{}/valid/{}\".format(phase,exp_name),val_preds)\n",
    "        store.append(\"/{}/test/{}\".format(phase,exp_name),test_preds)  \n",
    "                     \n",
    "        store.append(\"/summary\",pd.DataFrame(data={\"phase\":[phase],\n",
    "                                                   \"exp\":[exp_name],\n",
    "                                                   \"train_log_loss\":[train_log_loss],\n",
    "                                                   \"val_log_loss\":[valid_log_loss], \n",
    "                                                   \"LB\":[LB_score] }) )  \n",
    "\n",
    "        store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_results_h5(\"ph1\",exp_name,train_preds,val_preds,submission,train_log_loss,valid_log_loss,0.318)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = pd.HDFStore('data/results.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.80484443],\n",
       "       [ 0.80484443,  1.        ]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(store.select(\"/ph1/valid/_5fold_baseline\").values.ravel(), store.select(\"/ph1/train/_5fold_baseline\").values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/summary',\n",
       " '/ph1/test/_3fold_baseline',\n",
       " '/ph1/test/_5fold_baseline',\n",
       " '/ph1/test/_5fold_fcn',\n",
       " '/ph1/train/_3fold_baseline',\n",
       " '/ph1/train/_5fold_baseline',\n",
       " '/ph1/train/_5fold_fcn',\n",
       " '/ph1/valid/_3fold_baseline',\n",
       " '/ph1/valid/_5fold_baseline',\n",
       " '/ph1/valid/_5fold_fcn']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark3cv = pd.read_csv(\"subm/sub_benchmark.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark3cv.set_index('id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_iceberg_3cv</th>\n",
       "      <th>is_iceberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_iceberg_3cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_iceberg</th>\n",
       "      <td>0.975071</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                is_iceberg_3cv  is_iceberg\n",
       "is_iceberg_3cv        1.000000    0.975071\n",
       "is_iceberg            0.975071    1.000000"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark3cv.join(store.get(\"/ph1/test/_5fold_baseline\"),lsuffix=\"_3cv\").corr()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
